{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5b861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일: logP_95205.csv 에서 중복된 SMILES 발견:\n",
      "                                               SMILES\n",
      "93  C1CC1C2=NC3=CC=CC=C3C(=C2/C=C/[C@H](C[C@H](CC(...\n",
      "94  C1CC1C2=NC3=CC=CC=C3C(=C2/C=C/[C@H](C[C@H](CC(...\n",
      "파일: logP_29167.csv 에서 중복된 SMILES 없음.\n",
      "병합된 데이터에서 중복된 SMILES 발견:\n",
      "                                               SMILES\n",
      "93  C1CC1C2=NC3=CC=CC=C3C(=C2/C=C/[C@H](C[C@H](CC(...\n",
      "94  C1CC1C2=NC3=CC=CC=C3C(=C2/C=C/[C@H](C[C@H](CC(...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ./data/portal_set/ 디렉토리 경로\n",
    "data_dir = './data/portal_set/'\n",
    "\n",
    "# logP_*.csv 파일만 선택\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.startswith('logP_') and f.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'SMILES' in df.columns:\n",
    "            duplicated = df[df.duplicated(subset=['SMILES'], keep=False)]\n",
    "            if not duplicated.empty:\n",
    "                print(f\"파일: {file} 에서 중복된 SMILES 발견:\")\n",
    "                print(duplicated[['SMILES']])\n",
    "            else:\n",
    "                print(f\"파일: {file} 에서 중복된 SMILES 없음.\")\n",
    "        else:\n",
    "            print(f\"파일: {file} 에 'SMILES' 컬럼이 없음.\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일: {file} 읽기 오류: {e}\")\n",
    "\n",
    "# 두 개의 파일을 merge하고 중복을 재확인하는 코드입니다.\n",
    "# 예시로 logP_로 시작하는 첫 두 파일을 사용합니다.\n",
    "if len(csv_files) >= 2:\n",
    "    file1 = os.path.join(data_dir, csv_files[0])\n",
    "    file2 = os.path.join(data_dir, csv_files[1])\n",
    "    try:\n",
    "        df1 = pd.read_csv(file1)\n",
    "        df2 = pd.read_csv(file2)\n",
    "        merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "        if 'SMILES' in merged_df.columns:\n",
    "            duplicated_merged = merged_df[merged_df.duplicated(subset=['SMILES'], keep=False)]\n",
    "            if not duplicated_merged.empty:\n",
    "                print(f\"병합된 데이터에서 중복된 SMILES 발견:\")\n",
    "                print(duplicated_merged[['SMILES']])\n",
    "            else:\n",
    "                print(\"병합된 데이터에서 중복된 SMILES 없음.\")\n",
    "        else:\n",
    "            print(\"병합된 데이터에 'SMILES' 컬럼이 없음.\")\n",
    "    except Exception as e:\n",
    "        print(f\"병합 과정에서 오류 발생: {e}\")\n",
    "else:\n",
    "    print(\"logP_로 시작하는 파일이 2개 이상 필요합니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970303bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMET_fin2.csv 파일 읽기 오류: Error tokenizing data. C error: Expected 1 fields in line 570, saw 2\n",
      "\n",
      "모든 파일 병합 후 중복된 SMILES 발견:\n",
      "                                                 SMILES\n",
      "0                                 CC(=O)NC1=CC=C(C=C1)O\n",
      "1                          C1=NC2=C(N1COCCO)N=C(NC2=O)N\n",
      "2     C[C@H]1[C@H]([C@H](C[C@@H](O1)O[C@H]2C[C@@](CC...\n",
      "3                  CN(C)CCC=C1C2=CC=CC=C2CCC3=CC=CC=C31\n",
      "6     C[C@@H]1CC[C@H]2[C@H]([C@H](O[C@H]3[C@@]24[C@H...\n",
      "...                                                 ...\n",
      "965   C1CC(CCC1C2=CC=C(C=C2)Cl)C3=C(C4=CC=CC=C4C(=O)...\n",
      "1087    CC1=C(N=C(N1C2=CC=C(C=C2)F)C)C#CC3=CC(=NC=C3)Cl\n",
      "1132  CCCCCCCCCCNCCN[C@]1(C[C@@H](O[C@H]([C@H]1O)C)O...\n",
      "1145  CC(C)C[C@@H]1CN2CCC3=CC(=C(C=C3[C@H]2C[C@H]1OC...\n",
      "1221  CC(C)(CC1=CC=C(C=C1)OC)NC[C@@H](C2=C3C(=CC(=C2...\n",
      "\n",
      "[79 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 병합할 파일들이 있는 디렉토리\n",
    "data_dir = './data/portal_set/'\n",
    "\n",
    "# logP_*.csv, ADMET_*.csv 파일과 kist_logp_Fup.csv 파일 리스트업\n",
    "logp_files = [f for f in os.listdir(data_dir) if f.startswith('logP_') and f.endswith('.csv')]\n",
    "admet_files = [f for f in os.listdir(data_dir) if f.startswith('ADMET_') and f.endswith('.csv')]\n",
    "kist_file = 'kist_logp_Fup.csv'  # 해당 파일이 data_dir에 있다고 가정\n",
    "\n",
    "# 파일 경로 리스트 생성\n",
    "all_files = [os.path.join(data_dir, f) for f in (logp_files + admet_files)]\n",
    "kist_path = os.path.join(data_dir, kist_file)\n",
    "if os.path.exists(kist_path):\n",
    "    all_files.append(kist_path)\n",
    "else:\n",
    "    print(f\"{kist_file} 파일이 {data_dir}에 존재하지 않습니다.\")\n",
    "\n",
    "# 각 파일에서 SMILES 컬럼이 있는 데이터만 읽어서 병합\n",
    "dfs = []\n",
    "for file_path in all_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'SMILES' in df.columns:\n",
    "            dfs.append(df[['SMILES']].copy())\n",
    "        else:\n",
    "            print(f\"{os.path.basename(file_path)} 파일에 'SMILES' 컬럼이 없습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(file_path)} 파일 읽기 오류: {e}\")\n",
    "\n",
    "if len(dfs) > 0:\n",
    "    merged_smiles = pd.concat(dfs, ignore_index=True)\n",
    "    duplicated = merged_smiles[merged_smiles.duplicated(subset=['SMILES'], keep=False)]\n",
    "    if not duplicated.empty:\n",
    "        print(\"모든 파일 병합 후 중복된 SMILES 발견:\")\n",
    "        print(duplicated['SMILES'].drop_duplicates().to_frame())\n",
    "    else:\n",
    "        print(\"모든 파일 병합 후 중복된 SMILES 없음.\")\n",
    "else:\n",
    "    print(\"병합할 SMILES 데이터가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c8a3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 데이터가 ./data/portal_set/merged_admet.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# 지정된 컬럼명\n",
    "columns = [\n",
    "    \"SMILES\",\n",
    "    \"molecular_weight\",\n",
    "    \"logP\",\n",
    "    \"pKa\",\n",
    "    \"solubility\",\n",
    "    \"permeability\",\n",
    "    \"plasma_protein_binding\",\n",
    "    \"fu_in_vitro\"\n",
    "]\n",
    "\n",
    "# 병합할 파일들이 있는 디렉토리\n",
    "data_dir = './data/portal_set/'\n",
    "\n",
    "# ADMET_*.csv 파일 경로 수집 (경로 오류 수정: 중복 portal_set 제거)\n",
    "admet_files = glob.glob(os.path.join(data_dir, \"ADMET_*.csv\"))\n",
    "\n",
    "# SMILES를 기준으로 병합할 데이터프레임 생성\n",
    "merged_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for file_path in admet_files:\n",
    "    try:\n",
    "        # ADMET_fin2.csv 파일은 구분자가 콤마(,)가 아니라 탭(\\t)임을 감안하여 처리\n",
    "        if os.path.basename(file_path) == \"ADMET_fin2.csv\":\n",
    "            df = pd.read_csv(file_path, delimiter='\\t')\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "        # SMILES 컬럼이 없으면 건너뜀\n",
    "        if 'SMILES' not in df.columns:\n",
    "            print(f\"{os.path.basename(file_path)} 파일에 'SMILES' 컬럼이 없습니다.\")\n",
    "            continue\n",
    "        # 병합 대상 컬럼만 추출 (SMILES + columns에 있는 컬럼)\n",
    "        use_cols = [col for col in columns if col in df.columns]\n",
    "        sub_df = df[[\"SMILES\"] + [col for col in use_cols if col != \"SMILES\"]].copy()\n",
    "        # SMILES 기준으로 병합\n",
    "        for idx, row in sub_df.iterrows():\n",
    "            smiles = row[\"SMILES\"]\n",
    "            # 이미 해당 SMILES가 있으면 해당 컬럼만 업데이트\n",
    "            if smiles in merged_df[\"SMILES\"].values:\n",
    "                for col in use_cols:\n",
    "                    if col == \"SMILES\":\n",
    "                        continue\n",
    "                    val = row.get(col, np.nan)\n",
    "                    # 기존 값이 결측치이고 새 값이 결측치가 아니면 업데이트\n",
    "                    mask = merged_df[\"SMILES\"] == smiles\n",
    "                    if col in merged_df.columns:\n",
    "                        # 여러 행이 있을 수 있으므로 첫 번째 값만 확인\n",
    "                        current_val = merged_df.loc[mask, col].values[0]\n",
    "                        if pd.isna(current_val) and not pd.isna(val):\n",
    "                            merged_df.loc[mask, col] = val\n",
    "            else:\n",
    "                # 새로운 SMILES면 빈 row 생성 후 값 입력\n",
    "                new_row = dict.fromkeys(columns, np.nan)\n",
    "                new_row[\"SMILES\"] = smiles\n",
    "                for col in use_cols:\n",
    "                    if col != \"SMILES\":\n",
    "                        new_row[col] = row.get(col, np.nan)\n",
    "                merged_df = pd.concat([merged_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(file_path)} 파일 읽기 오류: {e}\")\n",
    "\n",
    "# 데이터가 비어있지 않을 때만 저장\n",
    "output_path = os.path.join(data_dir, \"merged_admet.csv\")\n",
    "if not merged_df.empty:\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"병합된 데이터가 {output_path}에 저장되었습니다.\")\n",
    "else:\n",
    "    print(\"병합된 데이터가 없어 저장하지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba0c8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_831270/2360646423.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 데이터가 ./data/portal_set/merged_log_caco2_fup.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 병합할 파일 경로 지정\n",
    "data_dir = \"./data/portal_set\"\n",
    "log_files = glob.glob(os.path.join(data_dir, \"logP_*.csv\"))\n",
    "caco2_files = glob.glob(os.path.join(data_dir, \"caco2_*.csv\"))\n",
    "# fu_files = glob.glob(os.path.join(data_dir, \"*Fup*.csv\"))\n",
    "\n",
    "# 최종 병합 데이터프레임 생성\n",
    "columns = [\"SMILES\", \"logP\", \"permeability\", \"fu_in_vitro\"]\n",
    "merged_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# log 파일 처리 (logP)\n",
    "for file_path in log_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if \"SMILES\" not in df.columns or \"value\" not in df.columns:\n",
    "            continue\n",
    "        for idx, row in df.iterrows():\n",
    "            smiles = row[\"SMILES\"]\n",
    "            logp = row[\"value\"]\n",
    "            mask = merged_df[\"SMILES\"] == smiles\n",
    "            if mask.any():\n",
    "                # 이미 있으면 logP만 업데이트\n",
    "                if pd.isna(merged_df.loc[mask, \"logP\"].values[0]) and not pd.isna(logp):\n",
    "                    merged_df.loc[mask, \"logP\"] = logp\n",
    "            else:\n",
    "                new_row = dict.fromkeys(columns, np.nan)\n",
    "                new_row[\"SMILES\"] = smiles\n",
    "                new_row[\"logP\"] = logp\n",
    "                merged_df = pd.concat([merged_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(file_path)} 파일 처리 중 오류: {e}\")\n",
    "\n",
    "# caco2 파일 처리 (permeability)\n",
    "for file_path in caco2_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if \"SMILES\" not in df.columns or \"value\" not in df.columns:\n",
    "            continue\n",
    "        for idx, row in df.iterrows():\n",
    "            smiles = row[\"SMILES\"]\n",
    "            permeability = row[\"value\"]\n",
    "            mask = merged_df[\"SMILES\"] == smiles\n",
    "            if mask.any():\n",
    "                if pd.isna(merged_df.loc[mask, \"permeability\"].values[0]) and not pd.isna(permeability):\n",
    "                    merged_df.loc[mask, \"permeability\"] = permeability\n",
    "            else:\n",
    "                new_row = dict.fromkeys(columns, np.nan)\n",
    "                new_row[\"SMILES\"] = smiles\n",
    "                new_row[\"permeability\"] = permeability\n",
    "                merged_df = pd.concat([merged_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(file_path)} 파일 처리 중 오류: {e}\")\n",
    "\n",
    "# # fu_in_vitro 파일 처리 (fu_in_vitro)\n",
    "# for file_path in fu_files:\n",
    "#     try:\n",
    "#         df = pd.read_csv(file_path)\n",
    "#         # Fup 컬럼명 확인\n",
    "#         fup_col = None\n",
    "#         for col in df.columns:\n",
    "#             if col.lower() == \"fup\":\n",
    "#                 fup_col = col\n",
    "#                 break\n",
    "#         if \"SMILES\" not in df.columns or fup_col is None:\n",
    "#             continue\n",
    "#         for idx, row in df.iterrows():\n",
    "#             smiles = row[\"SMILES\"]\n",
    "#             fu = row[fup_col]\n",
    "#             mask = merged_df[\"SMILES\"] == smiles\n",
    "#             if mask.any():\n",
    "#                 if pd.isna(merged_df.loc[mask, \"fu_in_vitro\"].values[0]) and not pd.isna(fu):\n",
    "#                     merged_df.loc[mask, \"fu_in_vitro\"] = fu\n",
    "#             else:\n",
    "#                 new_row = dict.fromkeys(columns, np.nan)\n",
    "#                 new_row[\"SMILES\"] = smiles\n",
    "#                 new_row[\"fu_in_vitro\"] = fu\n",
    "#                 merged_df = pd.concat([merged_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "#     except Exception as e:\n",
    "#         print(f\"{os.path.basename(file_path)} 파일 처리 중 오류: {e}\")\n",
    "\n",
    "# SMILES 기준 중복 제거 (마지막 값 우선)\n",
    "merged_df = merged_df.drop_duplicates(subset=[\"SMILES\"], keep=\"last\").reset_index(drop=True)\n",
    "\n",
    "# 저장\n",
    "output_path = os.path.join(data_dir, \"merged_log_caco2_fup.csv\")\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"병합된 데이터가 {output_path}에 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
